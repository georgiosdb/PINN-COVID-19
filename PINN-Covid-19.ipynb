{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-informed machine learning for the COVID-19 pandemic: <br>Adherence to social distancing and short-term predictions for eight countries\n",
    "\n",
    "### G. D. Barmparis and G. P. Tsironis\n",
    "\n",
    "Preprint: https://arxiv.org/abs/2008.08162v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set the font size to 18pt for all the plots.\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Machine Learning packages\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countries. (SWt0 : First day for the second wave, since the first case in each country.) \n",
    "countries = {        \"Greece\" : {\"SWt0\" : 97},\n",
    "             \"United States\"  : {\"SWt0\" : 127},\n",
    "             \"United Kingdom\" : {\"SWt0\" : 134},\n",
    "                    \"Germany\" : {\"SWt0\" : 160},\n",
    "                     \"France\" : {\"SWt0\" : 130},\n",
    "                \"Netherlands\" : {\"SWt0\" : 126},\n",
    "                      \"Italy\" : {\"SWt0\" : 138},\n",
    "                      \"Spain\" : {\"SWt0\" : 140}\n",
    "            }\n",
    "\n",
    "runOnly = [\"Greece\"] # Use 'All' to run them all!\n",
    "if \"All\" in runOnly : runOnly = list(countries.keys())\n",
    "  \n",
    "# Kind of data\n",
    "kind = \"new_cases\" # or new_deaths\n",
    "\n",
    "# Number of days for short term predictions.\n",
    "nOfShortPredDays = 7 \n",
    "\n",
    "# Number of days for long term predictions.\n",
    "nOfLongPredDays  = 4*7\n",
    "\n",
    "# Number of days for smoothing plus minus the given date. Average on 2*nOfDaysSmoothing + 1 days.\n",
    "nOfDaysSmoothing = 3\n",
    "\n",
    "# Number of grid-point for the SIR model.\n",
    "nOfSIRPoints = 500\n",
    "\n",
    "# Use pre-trained model.\n",
    "loadModel = True\n",
    "\n",
    "# Patience before early stopping.\n",
    "patience = 50\n",
    "\n",
    "# Display progress every \"displayStep\" epochs.\n",
    "displayStep = 50\n",
    "\n",
    "# Total possible number of epochs.\n",
    "epochs = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from https://covid.ourworldindata.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://covid.ourworldindata.org/data/owid-covid-data.csv\"\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data driven mean squeared error.\n",
    "def loss_MSE(y_true, y_pred) :\n",
    "  #\n",
    "  lossMSE = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "  #\n",
    "  return lossMSE\n",
    "\n",
    "# PINN-SIR loss.\n",
    "def sir(model, xTrainSIR, mu):\n",
    "  #\n",
    "  tTensor = tf.convert_to_tensor(xTrainSIR)\n",
    "  tModelA = xTrainSIR.flatten()\n",
    "  #\n",
    "  with tf.GradientTape() as g:\n",
    "    g.watch(tTensor)\n",
    "    with tf.GradientTape() as gg:\n",
    "      gg.watch(tTensor)\n",
    "      x = model(tTensor)\n",
    "    x_t = gg.gradient(x, tTensor)\n",
    "    #\n",
    "  x_tt = g.gradient(x_t, tTensor)\n",
    "  #\n",
    "  aa  = sigma*tModelA + sigma0\n",
    "  a_t = [sigma]*len(tModelA)\n",
    "  #\n",
    "  del g, gg\n",
    "  #\n",
    "  return tf.abs(x_tt + ((sigma*tModelA + sigma0)*tf.exp(x) - sigma/(sigma*tModelA + sigma0))*(x_t + mu))**2\n",
    "\n",
    "\n",
    "def loss_SIR() :\n",
    "  #\n",
    "  lossSIR = sir(model, xTrainSIR, mu)\n",
    "  #\n",
    "  return lossSIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define an Early Stopping class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping :\n",
    "  #\n",
    "  def __init__(self, model, patience, displayStep, realData, trainData, tPredict) :\n",
    "    #\n",
    "    self.step = 0\n",
    "    #\n",
    "    self.fn = open(os.path.join(\"SecondWave_%s\" % country, \"%s_output\" % country), \"a+\")\n",
    "    #\n",
    "    self.model = model\n",
    "    #\n",
    "    self.patience = patience\n",
    "    #\n",
    "    self.displayStep = displayStep\n",
    "    self.tData, self.yData = realData\n",
    "    self.tTrainData, self.yTrainData = trainData\n",
    "    self.tPredict = tPredict\n",
    "    #\n",
    "    self.best = np.inf\n",
    "    self.wait = 0\n",
    "    #\n",
    "    self.best_model = None\n",
    "    self.best_weights = None\n",
    "    self.bestSigma = None\n",
    "    self.bestSigma0 = None\n",
    "    self.bestM = None\n",
    "    #\n",
    "    self.stopped_epoch = 0\n",
    "    self.stop_training = False\n",
    "\n",
    "  def on_epoch_end(self, epoch, losses) :\n",
    "    #\n",
    "    mse, pi, current = losses[\"MSE_Data\"], losses[\"MSE_SIR\"], losses[\"TotLoss\"]\n",
    "    #\n",
    "    if current < 1.e-5 :\n",
    "      #\n",
    "      self.stopped_epoch = epoch\n",
    "      #\n",
    "      self.model.set_weights(self.best_weights)\n",
    "      self.model.save(os.path.join(\"SecondWave_%s\" % country, \"%s_SIR.h5\" % country))\n",
    "      #\n",
    "      log = \"Epoch %05d: early stopping. %s\" % (self.stopped_epoch + 1, \" \".join(\"%s : %12.6f \" % (k,v) for k,v in losses.items()))\n",
    "      #\n",
    "      print(log)\n",
    "      #\n",
    "      self.fn.write(\"%s\\n\" % log)\n",
    "      #\n",
    "      self.plotBestState(epoch)\n",
    "      #\n",
    "      self.plotPredictions()\n",
    "      #\n",
    "      self.stop_training = True\n",
    "      #\n",
    "    else :\n",
    "      #\n",
    "      if np.less(current, self.best) :\n",
    "        #\n",
    "        self.best = current\n",
    "        self.wait = 0\n",
    "        #\n",
    "        # Keep best weights.\n",
    "        self.best_model = self.model\n",
    "        self.best_weights = self.model.get_weights()\n",
    "        self.bestSigma = sigma.numpy()\n",
    "        self.bestSigma0 = sigma0.numpy()\n",
    "        self.bestM = mu.numpy()\n",
    "        #\n",
    "      else :\n",
    "        #\n",
    "        self.wait += 1\n",
    "        #\n",
    "        if self.wait >= self.patience:\n",
    "          #\n",
    "          self.stopped_epoch = epoch\n",
    "          #\n",
    "          log = \"Restoring model weights from the end of the best epoch.\"\n",
    "          print(log)\n",
    "          #\n",
    "          self.fn.write(\"%s\\n\" % log)\n",
    "          self.fn.flush()\n",
    "          #\n",
    "          self.model.set_weights(self.best_weights) \n",
    "          self.best_model = self.model\n",
    "          #\n",
    "          self.model.save(os.path.join(\"SecondWave_%s\" % country, \"%s_SIR.h5\" % country))\n",
    "          #\n",
    "          log = \"Early Stopping!\\nEpoch:%6i, Loss: %12.6f, N: %i, Best parameters: sigma: %.6f, sigma0: %.6f, Mu: %.6f, R0:%.6f\" % ( self.stopped_epoch + 1, self.best, N, self.bestSigma, self.bestSigma0, self.bestM, self.bestSigma0/self.bestM )\n",
    "          print(log)\n",
    "          #\n",
    "          self.fn.write(\"%s\\n\" % log)\n",
    "          self.fn.flush()\n",
    "          #\n",
    "          self.plotBestState(epoch)\n",
    "          #\n",
    "          self.plotPredictions()\n",
    "          #\n",
    "          self.stop_training = True\n",
    "          #\n",
    "    self.step += 1\n",
    "    #\n",
    "    if not self.stop_training : \n",
    "      #\n",
    "      log = \"Epoch:%6i, N: %i, %s, S: %.6f, S0: %.6f, Mu: %.6f, R0:%.6f, P:%i\" % (epoch + 1, N, \" \".join(\"%s: %12.6f \" % (k,v) for k,v in losses.items()), sigma.numpy(), sigma0.numpy(), mu.numpy(), sigma0.numpy()/mu.numpy(), self.wait)\n",
    "      #\n",
    "      print(log)\n",
    "      #\n",
    "      self.fn.write(\"%s\\n\" % log)\n",
    "      self.fn.flush()\n",
    "      #\n",
    "      if self.step == 1 or self.step%(self.displayStep) == 0 : \n",
    "        self.plotBestState(epoch)\n",
    "    #\n",
    "    return self.stop_training\n",
    "\n",
    "\n",
    "  def plotBestState(self, epoch) :\n",
    "    #\n",
    "    fig, ax1 = plt.subplots( figsize = (18, 8) )\n",
    "    #\n",
    "    plt.title(\"%s. $\\sigma$: %.6f $\\sigma_0$: %.6f $\\mu$: %.6f $R_0$: %.6f\" % (country, self.bestSigma, self.bestSigma0, self.bestM, self.bestSigma0/self.bestM))\n",
    "    #\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('I(t)', color = 'k')\n",
    "    #\n",
    "    # Original Data\n",
    "    ax1.plot(self.tData, (N-N0)*self.yData + N0, 'go', markersize = 8, label = 'Reported data')\n",
    "    #\n",
    "    # Training Data\n",
    "    ax1.plot(self.tTrainData, (N-N0)*np.exp(self.yTrainData) + N0, 'ro', markersize = 8, label = 'Training data')\n",
    "    #\n",
    "    # Predicted values at xValues PINN\n",
    "    ax1.plot(self.tPredict, (N-N0)*np.exp(self.best_model.predict(self.tPredict)) + N0, color = \"orange\", label = 'PINN')\n",
    "    #\n",
    "    ax1.tick_params(axis = 'y', labelcolor = \"k\")\n",
    "    plt.legend(loc = \"upper left\")\n",
    "    \n",
    "    ax1.set_xticks(tData[::7])\n",
    "    ax1.set_xticklabels(dateTicks[::7])\n",
    "    plt.setp(ax1.get_xticklabels(), rotation = 45, ha = \"right\", rotation_mode = \"anchor\")\n",
    "    #\n",
    "    ax1.grid()\n",
    "    #\n",
    "    ax2 = ax1.twinx()  # Instantiate a second axes that shares the same x-axis\n",
    "    #\n",
    "    # Plot a(t)\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('a(t)', color = 'b')\n",
    "    #\n",
    "    ax2.plot(self.tPredict, self.bestSigma*self.tPredict + self.bestSigma0 , \"b-\", label = \"a(t)\")\n",
    "    ax2.plot(self.tPredict, [self.bestM]*len(self.tPredict), \"k--\", label = \"$\\mu$\")\n",
    "    #\n",
    "    ax2.legend(loc = \"upper right\")\n",
    "    ax2.tick_params(axis = 'y', labelcolor = 'b')\n",
    "    #    \n",
    "    fig.tight_layout()\n",
    "    #\n",
    "    plt.savefig(os.path.join(\"SecondWave_%s\" % country, \"%s_Best_%i.svg\" % (country, epoch+1)),\n",
    "                dpi = 300, orientation='landscape', format = 'svg')\n",
    "    #\n",
    "    plt.show()\n",
    "    #\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "  def plotPredictions(self) :\n",
    "    #\n",
    "    fig = plt.figure( figsize = (18, 8) )\n",
    "    #\n",
    "    plt.title(\"%s\" % country)\n",
    "    #\n",
    "    color = 'tab:red'\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('I(t)', color = 'k')\n",
    "    #\n",
    "    # Original Data\n",
    "    plt.plot(self.tData, (N-N0)*self.yData + N0, 'go', markersize = 8, label = 'Reported data')\n",
    "    #\n",
    "    # Predicted values during Training.\n",
    "    plt.plot(self.tPredict, (N-N0)*np.exp(self.best_model.predict(self.tPredict)) + N0, color = \"C1\", marker = \"o\", markersize = 5)\n",
    "    #\n",
    "    # Short Term Predictions\n",
    "    tShortPred = np.linspace(nOfDays, nOfDays + nOfShortPredDays - 1, nOfShortPredDays)\n",
    "    plt.plot(tShortPred, (N-N0)*np.exp(self.best_model.predict(tShortPred))+ N0, color = 'C1', marker = \"o\", ls = \"\", fillstyle = 'none', markersize = 8, label = 'Short Term Predictions')\n",
    "    #\n",
    "    # Long Term Predictions\n",
    "    tLongPred = np.linspace(nOfDays + nOfShortPredDays, nOfDays + nOfShortPredDays + nOfLongPredDays - 1, nOfLongPredDays)\n",
    "    plt.plot(tLongPred, (N-N0)*np.exp(self.best_model.predict(tLongPred))+ N0, color = 'C1', ls = \"--\", label = 'Long Term Predictions')\n",
    "    #\n",
    "    if country == \"Greece\" :\n",
    "      plt.vlines(x = 159, ymin = 0, ymax = 1.1*N, ls = \"--\", color = \"r\")\n",
    "      plt.annotate(\"Lockdown\", xy = (160,50), color = \"r\")\n",
    "    #\n",
    "    plt.grid()\n",
    "    plt.legend(loc = \"upper left\")\n",
    "    #\n",
    "    tTicks = range(nOfDays + nOfShortPredDays + nOfLongPredDays)\n",
    "    #\n",
    "    plt.xticks(tTicks[::7], dateTicks[::7], rotation = 45, ha = \"right\", rotation_mode = \"anchor\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    #\n",
    "    plt.savefig(os.path.join(\"SecondWave_%s\" % country, \"%s_Predictions.svg\" % (country)),\n",
    "                dpi = 300, orientation = 'landscape', format = 'svg')\n",
    "    #\n",
    "    plt.savefig(os.path.join(\"SecondWave_%s\" % country, \"%s_Predictions.jpeg\" % (country)),\n",
    "                dpi = 300, orientation = 'landscape', format = 'jpeg')\n",
    "    #\n",
    "    plt.show()\n",
    "    #\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code for each one of the selected countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, params in countries.items() :\n",
    "  #\n",
    "  if country in runOnly :\n",
    "    #\n",
    "    # Index of the first day of the second wave.\n",
    "    t0 = params[\"SWt0\"]\n",
    "    #\n",
    "    # Make a folder for the given country.\n",
    "    if not os.path.exists(\"SecondWave_%s\" % country) : os.mkdir(\"SecondWave_%s\" % country)\n",
    "    #\n",
    "    # Country's data\n",
    "    cntryOriginal = data[data[\"location\"] == country]\n",
    "    #\n",
    "    # Keep only the dates after the first case.\n",
    "    cntryCases = cntryOriginal[kind][cntryOriginal[\"total_%s\" % kind.split(\"_\")[1]] > 0].values.astype(\"float64\")\n",
    "    # Dates\n",
    "    dates = cntryOriginal[\"date\"][cntryOriginal[\"total_%s\" % kind.split(\"_\")[1]] > 0].values    \n",
    "    #    \n",
    "    # Fill gaps with ones.\n",
    "    cntryCases[cntryCases < 1] = 1\n",
    "    #\n",
    "    # Keep only the second wave.\n",
    "    cntryCases = cntryCases[t0:]\n",
    "    dates = dates[t0:]\n",
    "    #\n",
    "    # Add the current day cases.\n",
    "    #cntryCases = np.append(cntryCases, 916)\n",
    "    #\n",
    "    # Number of days for the second wave.\n",
    "    nOfDays = len(cntryCases)\n",
    "    #\n",
    "    # Keep date zero ( One day before the first date with non-zero cases ).\n",
    "    dateZero = datetime.strptime(dates[0], '%Y-%m-%d') - timedelta(days = 1)\n",
    "    # and the last date.\n",
    "    dateLast = str(datetime.strptime(dates[-1], '%Y-%m-%d') + timedelta(days = 1)).split()[0]\n",
    "    #\n",
    "    dateZero = str(dateZero).split()[0]\n",
    "    #\n",
    "    # Check for missing data and create Country's date labels.\n",
    "    lastDateFound = False\n",
    "    dateTicks = [\"%s\" % dateZero[5:]]\n",
    "    #\n",
    "    for d in range(1, nOfDays + nOfShortPredDays + nOfLongPredDays) :\n",
    "      #\n",
    "      nextDate = str(datetime.strptime(dateZero, '%Y-%m-%d') + timedelta(days = d)).split()[0]\n",
    "      #\n",
    "      if not lastDateFound :\n",
    "        if nextDate not in dates :\n",
    "          print (\"Missing date\", nextDate)\n",
    "          cntryCases = np.insert(cntryCases, d, 0)\n",
    "      #\n",
    "      if nextDate == dates[-1] : lastDateFound = True\n",
    "      #\n",
    "      dateTicks.append(\"%s\" % (nextDate[5:]))\n",
    "    #\n",
    "    # Time axis\n",
    "    tData   = np.linspace(0, nOfDays-1, nOfDays)\n",
    "    #\n",
    "    # Smooth and normalize the data.\n",
    "    #\n",
    "    # Min Max scaler.\n",
    "    N0, N = 0, max(cntryCases)\n",
    "    #\n",
    "    # Smoothing.\n",
    "    ItDataOr = cntryCases\n",
    "    #\n",
    "    ItData = []\n",
    "    if nOfDaysSmoothing > 0 : ItData.extend(ItDataOr[:nOfDaysSmoothing])\n",
    "    #\n",
    "    ItData.extend([sum(ItDataOr[i-nOfDaysSmoothing:i+nOfDaysSmoothing+1])/(2*nOfDaysSmoothing+1) for i in range(nOfDaysSmoothing,len(ItDataOr)-nOfDaysSmoothing)])\n",
    "    #\n",
    "    if nOfDaysSmoothing > 0 : ItData.extend(ItDataOr[-nOfDaysSmoothing:])\n",
    "    #\n",
    "    # Smoothed data.\n",
    "    ItData = np.array(ItData)\n",
    "    #\n",
    "    # Normalize.\n",
    "    ItData   = (ItData  -  N0)/(N-N0)\n",
    "    ItDataOr = (ItDataOr - N0)/(N-N0)\n",
    "    #\n",
    "    # Plot the normalized data.\n",
    "    fig, ax = plt.subplots( figsize = (18,6) )\n",
    "    #\n",
    "    plt.title(country)\n",
    "    #\n",
    "    # Plot the original data.\n",
    "    ax.plot(tData, cntryCases, \"ro\")\n",
    "    #\n",
    "    ax.set_ylabel(\"I(t)\")\n",
    "    #\n",
    "    # Plot the normalized and smoothed data.\n",
    "    ax1 = ax.twinx()\n",
    "    #\n",
    "    ax1.plot(tData, ItDataOr, \"ro\", label = \"Reported Data\")\n",
    "    ax1.plot(tData, ItData, \"bo\", fillstyle = \"none\", label = \"Smoothed Data\")\n",
    "    #\n",
    "    ax.grid()\n",
    "    #\n",
    "    ax1.set_xticks(tData[::7])\n",
    "    ax1.set_xticklabels(dateTicks[::7])\n",
    "    plt.setp(ax.get_xticklabels(), rotation = 45, ha = \"right\", rotation_mode = \"anchor\")\n",
    "    #\n",
    "    ax1.set_ylabel(\"Normalized I(t) (x %i)\" % N)\n",
    "    plt.xlabel(\"Date\")\n",
    "    #\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()    \n",
    "    #\n",
    "    # Initialize the random generator seed.\n",
    "    np.random.seed(45)\n",
    "    tf.random.set_seed(45)\n",
    "    #\n",
    "\n",
    "    # Trainig data.\n",
    "    # Data driven.\n",
    "    xTrain    = tData.reshape(-1,1)\n",
    "    xt = np.log(ItData)\n",
    "    yTrain    = xt.reshape(-1,1)\n",
    "\n",
    "    # PINN.\n",
    "    tSIR  = np.linspace(0, nOfDays-1, nOfSIRPoints+1)\n",
    "    xTrainSIR = tSIR.reshape(-1,1)\n",
    "\n",
    "    # Initialize the PINN-SIR variables\n",
    "    sigma  = tf.Variable([0.1], dtype = \"float64\")\n",
    "    sigma0 = tf.Variable([0.1], dtype = \"float64\")\n",
    "    #\n",
    "    mu = tf.Variable([0.1], dtype = \"float64\")\n",
    "    #\n",
    "    # Use pre-trained model.\n",
    "    if loadModel :\n",
    "      #\n",
    "      if os.path.exists( \"SecondWave_%s/%s_SIR.h5\" % (country, country) ) :\n",
    "        model = tf.keras.models.load_model(\"SecondWave_%s/%s_SIR.h5\" % (country, country) )\n",
    "        print(\"Loading pre-trained country's model!\")\n",
    "      else :\n",
    "        #\n",
    "        model = tf.keras.models.load_model('sim_SIR.h5')\n",
    "        print(\"Loading pre-trained SIR model!\")\n",
    "      #\n",
    "    # Train a model from scratch.\n",
    "    else :\n",
    "      #\n",
    "      # Xavier normal initializer.\n",
    "      initializer = tf.keras.initializers.GlorotNormal()\n",
    "      #\n",
    "      act = \"sigmoid\"\n",
    "      model = Sequential()\n",
    "      model.add(Dense( 100, input_shape = (1,), activation = act, kernel_initializer = initializer) )\n",
    "      model.add(Dense( 100, activation = act, kernel_initializer = initializer ))\n",
    "      model.add(Dense( 100, activation = act, kernel_initializer = initializer ))\n",
    "      model.add(Dense( 100, activation = act, kernel_initializer = initializer ))\n",
    "      model.add(Dense( 100, activation = act, kernel_initializer = initializer ))\n",
    "      #\n",
    "      model.add(Dense(1))\n",
    "      #\n",
    "\n",
    "    # Model's summary.\n",
    "    model.summary()\n",
    "    #\n",
    "    \n",
    "    # Create an optimizer usinf Adam.\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    # Creat a Logger object.\n",
    "    logger = EarlyStopping(model = model, patience = patience, displayStep = displayStep, \n",
    "                           realData  = (tData, ItDataOr),\n",
    "                           trainData = (tData, xt),\n",
    "                           tPredict  = tSIR)\n",
    "\n",
    "    # Store losses.\n",
    "    losses = []\n",
    "\n",
    "    # Custom training loop.\n",
    "    for epoch in range(epochs): \n",
    "      #\n",
    "      with tf.GradientTape(persistent = True) as tape:\n",
    "        #\n",
    "        # Data driven.\n",
    "        yPred = model(tData.reshape(-1,1), training = True)\n",
    "        #\n",
    "        # Compute the MSE_{D} value.\n",
    "        loss_valueMSE = loss_MSE(yTrain, yPred)\n",
    "        #\n",
    "        # Compute the MSE_{SIR}\n",
    "        loss_valueSIR = loss_SIR()\n",
    "        #\n",
    "        # Compute the total Loss function.\n",
    "        loss_value = loss_valueMSE + tf.reduce_mean(loss_valueSIR)\n",
    "        \n",
    "      # Retrieve the gradients of the trainable variables with respect to the loss.\n",
    "      grads  = tape.gradient(loss_value, model.trainable_weights)\n",
    "    \n",
    "      # Apply the gradients.\n",
    "      optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "  \n",
    "      # Retrieve the gradients of the trainable variables with respect to the loss_SIR.\n",
    "      gradsA = tape.gradient(loss_valueSIR, [sigma, sigma0, mu])\n",
    "      #\n",
    "      # Apply the gradients.  \n",
    "      optimizer.apply_gradients(zip(gradsA, [sigma, sigma0, mu]))\n",
    "      #    \n",
    "      losses.append( float(tf.reduce_mean(loss_value)) )\n",
    "      #\n",
    "      stop_training = logger.on_epoch_end(epoch, {\"MSE_Data\": float(tf.reduce_mean(loss_valueMSE)),\n",
    "                                                  \"MSE_SIR\" : float(tf.reduce_mean(loss_valueSIR)), \n",
    "                                                  \"TotLoss\" : float(tf.reduce_mean(loss_value))})\n",
    "      #\n",
    "      if stop_training : break    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
